---
title: "Pinguino (Predictions)"
author: "Duane Edmonds"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  out.width = "85%",
  fig.asp = 0.8,
  fig.align = "center",
  message = FALSE,
  warning = FALSE
)

library(tidymodels)
library(magrittr)
library(ggsci)

theme_set(theme_grey())
```

```{r data, include = FALSE}
library(palmerpenguins)

pinguinos <- penguins %>% 
  rename(
    culmen_length = bill_length_mm,
    culmen_depth = bill_depth_mm,
    flipper_length = flipper_length_mm,
    body_mass = body_mass_g
  )
```

<br>

### Data Set

I am using Allison Horst's [`palmerpinguins`](https://github.com/allisonhorst/palmerpenguins) data package for predictive analysis. The original data were collected and made available by Dr. Kristen Gorman at the Palmer Station research station in Antarctica, a member of the Long Term Ecological Research (LTER) network.

https://github.com/allisonhorst/palmerpenguins

The data set contains data (344 observations) for 3 different species of penguins, collected from 3 islands in the Palmer Archipelago, Antarctica.

```{r}
pinguinos %>% 
  head() %>% 
  knitr::kable()
```

<br>

### Exploratory Analysis

**Culmen length**, **culmen depth**, **flipper length**, **body mass**, **sex**, and **island** (6) can be used as predictors for species.

Let's try to visualize the data to get a sense of which predictors will be most useful.

```{r}
pinguinos %>% 
  ggplot(aes(culmen_length, culmen_depth)) +
    geom_point(
      aes(
        color = species
      ),
      size = 2.5,
      alpha = 0.8
    ) +
    labs(
      subtitle = "culmen depth and length",
      x = "culmen length (mm)",
      y = "culmen depth (mm)"
    ) +
    scale_color_jco()
```

Surprisingly, we could make good predictions based on culmen length and depth alone based on the chart. Supervised learning algorithms (e.g., k-nearest neighbors (k-NN), decision tree, random forest) should be effective with this data set. It might also be interesting to implement a neural network classifier using this data.

```{r}
pinguinos %>% 
  ggplot(aes(culmen_length, culmen_depth)) +
    geom_point(
      aes(
        color = species,
        alpha = body_mass,
        size = body_mass
      )
    ) +
    labs(
      subtitle = "culmen depth and length and body mass",
      x = "culmen length (mm)",
      y = "culmen depth (mm)",
      size = "body mass (g)",
      alpha = "body mass (g)"
    ) +
    scale_color_jco()
```

```{r}
pinguinos %>% 
  filter(!is.na(body_mass)) %>% 
  ggplot(aes(species, body_mass)) +
    geom_violin(
      aes(
        fill = species
      ),
      alpha = 0.8
    ) +
    geom_boxplot(
      width = 0.05,
      outlier.shape = NA
    ) +
    labs(
      subtitle = "body mass distribution by species",
      x = "",
      y = "body mass (g)"
    ) +
    scale_fill_jco()
```

Adding body mass as a predictor appears to further distinguish the species.

```{r, fig.asp = 2.0} 
pinguinos %>% 
  drop_na() %>% 
  ggplot(aes(culmen_length, culmen_depth)) +
    geom_point(
      aes(
        color = species,
        shape = sex
      ),
      size = 2.5,
      alpha = 0.8
    ) +
    labs(
      subtitle = "culmen depth and length, sex, and island",
      x = "culmen length (mm)",
      y = "culmen depth (mm)"
    ) +
    facet_grid(island ~ .) +
    scale_color_jco()
```

The island feature appears to allow even stronger predictions. The Gentoo species is only found in the Biscoe Islands, and Chinstrap species are found only on Dream Island in the data.

```{r, out.width = "75%"}
pinguinos %>% 
  ggplot(aes(flipper_length, body_mass)) +
    geom_point() +
    geom_smooth(
      method = "lm",
      color = "black",
      se = 0,
      size = 0.8
    ) +
    labs(
      title = "flipper length vs body mass",
      x = "flipper length (mm)",
      y = "body mass (g)"
    )
```

```{r, include = FALSE}
corr_flipper_to_mass <- pinguinos %>% 
  select(flipper_length, body_mass) %>% 
  filter(!is.na(flipper_length), !is.na(body_mass)) %>% 
  cor() %>% .[[2]]
```

The observed penguin flipper length and body mass show a significant positive correlation (**`r format(corr_flipper_to_mass, digits = 3)`**). For this reason, we've chosen to use one or the other as a predictor (not both).

<br>

### Supervised Learning Predictive Modeling

The `tidymodels` package was used to perform predictive analysis using random forests and k-nearest neighbors supervised machine learning classification algorithms.

<br>

#### Pre-Processing

```{r pre-process, include = FALSE}
# split training and test data
pinguino_split <- pinguinos %>% 
  filter(
    !is.na(culmen_length),
    !is.na(culmen_depth),
    !is.na(body_mass),
    !is.na(island),
    !is.na(sex)
  ) %>% 
  initial_split(
    prop = 0.8
  )

# define pre-processing recipe steps and process training data
pinguino_recipe <- training(pinguino_split) %>% 
  recipe(species ~ culmen_length + culmen_depth + body_mass + island + sex) %>% 
  step_center(
    all_numeric(),
    -all_outcomes()
  ) %>% # normalize predictors to a mean of zero
  step_scale(
    all_numeric(),
    -all_outcomes()
  ) %>% # normalize predictors to a standard deviation of one
  prep()

# perform same pre-processing steps on test data
pinguino_testing <- pinguino_recipe %>% 
  bake(testing(pinguino_split))

# extract training data
pinguino_training <- juice(pinguino_recipe)
```

The data has been split into training and test data sets using the `rsample` data sampling package with 80% of the observations used for training the model. All numeric predictors have been normalized to a mean of zero and standard deviation of one using the `recipe` package.

<br>

#### Random Forests

```{r train_random_forest, include = FALSE}
pinguino_forest <- rand_forest(trees = 200, mode = "classification") %>% 
  set_engine("randomForest") %>% 
  fit(species ~ culmen_length + culmen_depth + body_mass + island + sex, data = pinguino_training)
```

```{r predict_random_forest}
pinguino_forest_accuracy <- pinguino_forest %>% 
  predict(pinguino_testing) %>% 
  bind_cols(pinguino_testing) %>% 
  metrics(truth = species, estimate = .pred_class) %$% 
  .estimate
```

A **random forests** classification algorithm (`randomForest` package) was trained on the test data using the `parsnip` package. The predictors used were **culmen depth**, **culmen length**, **body mass**, **island**, and **sex** (3 numeric and 2 categorical). The number of trees was set to 200.

The trained model was used to generate predictions from the sampled test data, and the accuracy of the predictions was calculated using the `yardstick` package. The model's calculated accuracy is **`r format(pinguino_forest_accuracy[1] * 100, digits = 3)`%**, and the Cohen's κ coefficient is `r format(pinguino_forest_accuracy[2], digits = 3)`. The confusion matrix of results is below.

```{r forest_confusion_matrix, out.width = "70%"}
cm <- pinguino_forest %>% 
  predict(pinguino_testing) %>% 
  bind_cols(pinguino_testing) %>% 
  conf_mat(truth = species, estimate = .pred_class)

autoplot(cm, type = "heatmap")
``` 

<br>

#### k-Nearest Neighbors

```{r train_knn, include = FALSE}
pinguino_knn <- nearest_neighbor(mode = "classification", dist_power = 2, weight_func = "optimal") %>% 
  set_engine("kknn") %>% 
  fit(species ~ culmen_length + culmen_depth + body_mass, data = pinguino_training)
```

```{r predict_knn}
pinguino_knn_accuracy <- pinguino_knn %>% 
  predict(pinguino_testing) %>% 
  bind_cols(pinguino_testing) %>% 
  metrics(truth = species, estimate = .pred_class) %$% 
  .estimate
```

A **weighted k-nearest neighbors** classification algorithm (`kknn` package) was trained on the test data using the `parsnip` package. The three numeric predictors (**culmen depth**, **culmen length**, and **body mass**) were used, and Euclidean distance was used for distance calculation. The package default of 5 nearest neighbors was left unchanged. The "optimal" kernel weight function was used.

The trained model was used to generate predictions from the sampled test data, and the accuracy of the predictions was again calculated using the `yardstick` package. The model's calculated accuracy is **`r format(pinguino_knn_accuracy[1] * 100, digits = 3)`%**, and the Cohen's κ coefficient is `r format(pinguino_knn_accuracy[2], digits = 3)`. The resulting confusion matrix is below.

```{r knn_confusion, out.width = "70%"}
cm_knn <- pinguino_knn %>% 
  predict(pinguino_testing) %>% 
  bind_cols(pinguino_testing) %>% 
  conf_mat(truth = species, estimate = .pred_class)

autoplot(cm_knn, type = "heatmap")
``` 

<br>

#### Model Comparison

Each algorithm performed very well with this data set. In general, the performance of the random forests and k-nearest neighbors models is very similar within the limited model validation completed and the within variation caused by the training-test data sampling. The random forests model seems to perform slightly better. This stands to reason since the random forests model makes use of two additional categorical predictors. Detailed cross-validation has not been performed. Since the data set is small, no evaluation of relative computational efficiency has been explored.